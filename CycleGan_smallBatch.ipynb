{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 16                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: data/mnist_blur_pairs_small   \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \t[default: pix2pix]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: cycle_gan_mnist_small         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 160\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.378 M\n",
      "[Network G_B] Total number of parameters : 11.378 M\n",
      "[Network D_A] Total number of parameters : 2.765 M\n",
      "[Network D_B] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/cycle_gan_mnist_small/web...\n",
      "/home/project/anaconda3/envs/W-Net/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 1 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 2 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 80, time: 0.104, data: 0.153) D_A: 0.369 G_A: 0.808 cycle_A: 1.237 idt_A: 0.479 D_B: 0.280 G_B: 0.851 cycle_B: 0.963 idt_B: 0.561 \n",
      "End of epoch 3 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 4 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 160, time: 0.105, data: 0.004) D_A: 0.190 G_A: 0.417 cycle_A: 0.559 idt_A: 0.463 D_B: 0.368 G_B: 0.483 cycle_B: 0.894 idt_B: 0.225 \n",
      "saving the model at the end of epoch 5, iters 800\n",
      "End of epoch 5 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 6 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 7 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 80, time: 0.106, data: 0.180) D_A: 0.215 G_A: 0.341 cycle_A: 0.463 idt_A: 0.372 D_B: 0.280 G_B: 0.386 cycle_B: 0.784 idt_B: 0.202 \n",
      "End of epoch 8 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 9 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 160, time: 0.107, data: 0.005) D_A: 0.184 G_A: 0.373 cycle_A: 0.401 idt_A: 0.278 D_B: 0.241 G_B: 0.287 cycle_B: 0.577 idt_B: 0.157 \n",
      "saving the model at the end of epoch 10, iters 1600\n",
      "End of epoch 10 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 11 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 12 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 80, time: 0.107, data: 0.179) D_A: 0.228 G_A: 0.260 cycle_A: 0.590 idt_A: 0.468 D_B: 0.246 G_B: 0.310 cycle_B: 1.106 idt_B: 0.226 \n",
      "End of epoch 13 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 14 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 160, time: 0.108, data: 0.004) D_A: 0.177 G_A: 0.386 cycle_A: 0.242 idt_A: 0.391 D_B: 0.270 G_B: 0.294 cycle_B: 0.823 idt_B: 0.107 \n",
      "saving the model at the end of epoch 15, iters 2400\n",
      "End of epoch 15 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 16 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 17 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 80, time: 0.108, data: 0.174) D_A: 0.249 G_A: 0.192 cycle_A: 0.264 idt_A: 0.298 D_B: 0.273 G_B: 0.336 cycle_B: 0.571 idt_B: 0.124 \n",
      "End of epoch 18 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 19 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 160, time: 0.108, data: 0.004) D_A: 1.043 G_A: 1.420 cycle_A: 0.343 idt_A: 0.300 D_B: 0.251 G_B: 0.287 cycle_B: 0.636 idt_B: 0.116 \n",
      "saving the model at the end of epoch 20, iters 3200\n",
      "End of epoch 20 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 21 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 22 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 80, time: 0.109, data: 0.172) D_A: 0.219 G_A: 0.231 cycle_A: 0.215 idt_A: 0.298 D_B: 0.271 G_B: 0.318 cycle_B: 0.620 idt_B: 0.099 \n",
      "End of epoch 23 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 24 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 160, time: 0.109, data: 0.004) D_A: 0.167 G_A: 0.377 cycle_A: 0.328 idt_A: 0.357 D_B: 0.293 G_B: 0.399 cycle_B: 0.752 idt_B: 0.113 \n",
      "saving the model at the end of epoch 25, iters 4000\n",
      "End of epoch 25 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 26 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 27 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 80, time: 0.110, data: 0.175) D_A: 0.199 G_A: 0.464 cycle_A: 0.324 idt_A: 0.317 D_B: 0.243 G_B: 0.278 cycle_B: 0.776 idt_B: 0.122 \n",
      "End of epoch 28 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 29 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 160, time: 0.109, data: 0.004) D_A: 0.124 G_A: 0.864 cycle_A: 0.387 idt_A: 0.447 D_B: 0.231 G_B: 0.304 cycle_B: 1.177 idt_B: 0.126 \n",
      "saving the model at the end of epoch 30, iters 4800\n",
      "End of epoch 30 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 31 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 32 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 80, time: 0.110, data: 0.170) D_A: 0.126 G_A: 0.480 cycle_A: 0.276 idt_A: 0.292 D_B: 0.277 G_B: 0.425 cycle_B: 0.681 idt_B: 0.120 \n",
      "End of epoch 33 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 34 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 160, time: 0.109, data: 0.005) D_A: 0.094 G_A: 0.684 cycle_A: 0.428 idt_A: 0.333 D_B: 0.307 G_B: 0.371 cycle_B: 0.723 idt_B: 0.167 \n",
      "saving the model at the end of epoch 35, iters 5600\n",
      "End of epoch 35 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 36 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 37 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 80, time: 0.110, data: 0.176) D_A: 0.214 G_A: 0.137 cycle_A: 0.386 idt_A: 0.354 D_B: 0.167 G_B: 0.448 cycle_B: 0.778 idt_B: 0.155 \n",
      "End of epoch 38 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 39 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 160, time: 0.110, data: 0.004) D_A: 0.216 G_A: 0.303 cycle_A: 0.334 idt_A: 0.291 D_B: 0.361 G_B: 0.386 cycle_B: 0.735 idt_B: 0.137 \n",
      "saving the model at the end of epoch 40, iters 6400\n",
      "End of epoch 40 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 41 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 42 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 80, time: 0.112, data: 0.174) D_A: 0.206 G_A: 0.309 cycle_A: 0.223 idt_A: 0.381 D_B: 0.236 G_B: 0.226 cycle_B: 0.841 idt_B: 0.105 \n",
      "End of epoch 43 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 44 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 160, time: 0.112, data: 0.005) D_A: 0.176 G_A: 0.304 cycle_A: 0.180 idt_A: 0.237 D_B: 0.272 G_B: 0.338 cycle_B: 0.509 idt_B: 0.073 \n",
      "saving the model at the end of epoch 45, iters 7200\n",
      "End of epoch 45 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 46 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 47 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 80, time: 0.113, data: 0.176) D_A: 0.224 G_A: 0.207 cycle_A: 0.236 idt_A: 0.284 D_B: 0.287 G_B: 0.319 cycle_B: 0.608 idt_B: 0.095 \n",
      "End of epoch 48 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 49 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 160, time: 0.120, data: 0.004) D_A: 0.176 G_A: 0.447 cycle_A: 0.252 idt_A: 0.301 D_B: 0.317 G_B: 0.347 cycle_B: 0.647 idt_B: 0.087 \n",
      "saving the model at the end of epoch 50, iters 8000\n",
      "End of epoch 50 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 51 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 52 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 80, time: 0.113, data: 0.175) D_A: 0.235 G_A: 0.488 cycle_A: 0.278 idt_A: 0.350 D_B: 0.245 G_B: 0.329 cycle_B: 0.856 idt_B: 0.092 \n",
      "End of epoch 53 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 54 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 160, time: 0.113, data: 0.004) D_A: 0.200 G_A: 0.282 cycle_A: 0.178 idt_A: 0.310 D_B: 0.280 G_B: 0.291 cycle_B: 0.663 idt_B: 0.067 \n",
      "saving the model at the end of epoch 55, iters 8800\n",
      "End of epoch 55 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 56 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 57 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 80, time: 0.115, data: 0.172) D_A: 0.284 G_A: 0.589 cycle_A: 0.228 idt_A: 0.188 D_B: 0.234 G_B: 0.234 cycle_B: 0.446 idt_B: 0.078 \n",
      "End of epoch 58 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 59 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 160, time: 0.115, data: 0.004) D_A: 0.235 G_A: 0.330 cycle_A: 0.252 idt_A: 0.346 D_B: 0.256 G_B: 0.320 cycle_B: 0.879 idt_B: 0.082 \n",
      "saving the model at the end of epoch 60, iters 9600\n",
      "End of epoch 60 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 61 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 62 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 80, time: 0.123, data: 0.170) D_A: 0.252 G_A: 0.180 cycle_A: 0.223 idt_A: 0.227 D_B: 0.249 G_B: 0.370 cycle_B: 0.513 idt_B: 0.076 \n",
      "saving the latest model (epoch 63, total_iters 10000)\n",
      "End of epoch 63 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 64 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 160, time: 0.116, data: 0.005) D_A: 0.209 G_A: 0.347 cycle_A: 0.180 idt_A: 0.282 D_B: 0.281 G_B: 0.269 cycle_B: 0.582 idt_B: 0.081 \n",
      "saving the model at the end of epoch 65, iters 10400\n",
      "End of epoch 65 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 66 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 67 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 80, time: 0.116, data: 0.167) D_A: 0.207 G_A: 0.221 cycle_A: 0.187 idt_A: 0.323 D_B: 0.250 G_B: 0.299 cycle_B: 0.676 idt_B: 0.061 \n",
      "End of epoch 68 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 69 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 160, time: 0.116, data: 0.004) D_A: 0.240 G_A: 0.233 cycle_A: 0.191 idt_A: 0.298 D_B: 0.426 G_B: 0.516 cycle_B: 0.665 idt_B: 0.069 \n",
      "saving the model at the end of epoch 70, iters 11200\n",
      "End of epoch 70 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 71 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 72 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 80, time: 0.118, data: 0.173) D_A: 0.254 G_A: 0.289 cycle_A: 0.155 idt_A: 0.339 D_B: 0.253 G_B: 0.259 cycle_B: 0.915 idt_B: 0.069 \n",
      "End of epoch 73 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 74 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 160, time: 0.125, data: 0.004) D_A: 0.224 G_A: 0.265 cycle_A: 0.164 idt_A: 0.352 D_B: 0.304 G_B: 0.309 cycle_B: 0.752 idt_B: 0.063 \n",
      "saving the model at the end of epoch 75, iters 12000\n",
      "End of epoch 75 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 76 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 77 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 80, time: 0.118, data: 0.173) D_A: 0.212 G_A: 0.234 cycle_A: 0.157 idt_A: 0.413 D_B: 0.242 G_B: 0.268 cycle_B: 0.903 idt_B: 0.052 \n",
      "End of epoch 78 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 79 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 160, time: 0.118, data: 0.005) D_A: 0.213 G_A: 0.304 cycle_A: 0.198 idt_A: 0.297 D_B: 0.258 G_B: 0.363 cycle_B: 0.821 idt_B: 0.088 \n",
      "saving the model at the end of epoch 80, iters 12800\n",
      "End of epoch 80 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 81 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 82 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 80, time: 0.118, data: 0.176) D_A: 0.200 G_A: 0.296 cycle_A: 0.232 idt_A: 0.291 D_B: 0.256 G_B: 0.235 cycle_B: 0.655 idt_B: 0.072 \n",
      "End of epoch 83 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 84 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 160, time: 0.118, data: 0.004) D_A: 0.258 G_A: 0.593 cycle_A: 0.291 idt_A: 0.296 D_B: 0.257 G_B: 0.372 cycle_B: 0.633 idt_B: 0.112 \n",
      "saving the model at the end of epoch 85, iters 13600\n",
      "End of epoch 85 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 86 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 87 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 80, time: 0.118, data: 0.177) D_A: 0.215 G_A: 0.194 cycle_A: 0.238 idt_A: 0.276 D_B: 0.236 G_B: 0.232 cycle_B: 0.608 idt_B: 0.087 \n",
      "End of epoch 88 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 89 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 160, time: 0.119, data: 0.004) D_A: 0.612 G_A: 0.634 cycle_A: 0.157 idt_A: 0.233 D_B: 0.259 G_B: 0.217 cycle_B: 0.493 idt_B: 0.061 \n",
      "saving the model at the end of epoch 90, iters 14400\n",
      "End of epoch 90 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 91 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 92 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 80, time: 0.128, data: 0.176) D_A: 0.349 G_A: 0.584 cycle_A: 0.272 idt_A: 0.233 D_B: 0.246 G_B: 0.316 cycle_B: 0.512 idt_B: 0.074 \n",
      "End of epoch 93 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 94 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 160, time: 0.120, data: 0.004) D_A: 0.200 G_A: 0.483 cycle_A: 0.277 idt_A: 0.256 D_B: 0.222 G_B: 0.294 cycle_B: 0.617 idt_B: 0.138 \n",
      "saving the model at the end of epoch 95, iters 15200\n",
      "End of epoch 95 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 96 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 97 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 80, time: 0.120, data: 0.171) D_A: 0.244 G_A: 0.395 cycle_A: 0.265 idt_A: 0.240 D_B: 0.336 G_B: 0.300 cycle_B: 0.521 idt_B: 0.146 \n",
      "End of epoch 98 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 99 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 160, time: 0.129, data: 0.004) D_A: 0.202 G_A: 0.306 cycle_A: 0.198 idt_A: 0.248 D_B: 0.240 G_B: 0.246 cycle_B: 0.535 idt_B: 0.060 \n",
      "saving the model at the end of epoch 100, iters 16000\n",
      "End of epoch 100 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "End of epoch 101 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "End of epoch 102 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 80, time: 0.121, data: 0.176) D_A: 0.216 G_A: 0.180 cycle_A: 0.277 idt_A: 0.312 D_B: 0.217 G_B: 0.235 cycle_B: 0.682 idt_B: 0.120 \n",
      "End of epoch 103 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "End of epoch 104 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 160, time: 0.122, data: 0.004) D_A: 0.189 G_A: 0.266 cycle_A: 0.232 idt_A: 0.375 D_B: 0.255 G_B: 0.179 cycle_B: 0.833 idt_B: 0.090 \n",
      "saving the model at the end of epoch 105, iters 16800\n",
      "End of epoch 105 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "End of epoch 106 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "End of epoch 107 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 80, time: 0.122, data: 0.173) D_A: 0.227 G_A: 0.383 cycle_A: 0.232 idt_A: 0.296 D_B: 0.264 G_B: 0.248 cycle_B: 0.626 idt_B: 0.073 \n",
      "End of epoch 108 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "End of epoch 109 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 160, time: 0.133, data: 0.005) D_A: 0.258 G_A: 0.430 cycle_A: 0.142 idt_A: 0.284 D_B: 0.280 G_B: 0.245 cycle_B: 0.570 idt_B: 0.062 \n",
      "saving the model at the end of epoch 110, iters 17600\n",
      "End of epoch 110 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "End of epoch 111 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "End of epoch 112 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 80, time: 0.121, data: 0.178) D_A: 0.231 G_A: 0.459 cycle_A: 0.222 idt_A: 0.280 D_B: 0.326 G_B: 0.250 cycle_B: 0.605 idt_B: 0.087 \n",
      "End of epoch 113 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "End of epoch 114 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 160, time: 0.123, data: 0.004) D_A: 0.595 G_A: 0.673 cycle_A: 0.190 idt_A: 0.147 D_B: 0.252 G_B: 0.309 cycle_B: 0.390 idt_B: 0.067 \n",
      "saving the model at the end of epoch 115, iters 18400\n",
      "End of epoch 115 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "End of epoch 116 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "End of epoch 117 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 80, time: 0.123, data: 0.175) D_A: 0.217 G_A: 0.286 cycle_A: 0.167 idt_A: 0.277 D_B: 0.242 G_B: 0.212 cycle_B: 0.572 idt_B: 0.051 \n",
      "End of epoch 118 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "End of epoch 119 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 160, time: 0.124, data: 0.005) D_A: 0.210 G_A: 0.246 cycle_A: 0.157 idt_A: 0.230 D_B: 0.249 G_B: 0.195 cycle_B: 0.558 idt_B: 0.056 \n",
      "saving the model at the end of epoch 120, iters 19200\n",
      "End of epoch 120 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "End of epoch 121 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "End of epoch 122 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 80, time: 0.133, data: 0.172) D_A: 0.244 G_A: 0.187 cycle_A: 0.121 idt_A: 0.359 D_B: 0.245 G_B: 0.331 cycle_B: 0.799 idt_B: 0.044 \n",
      "End of epoch 123 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "End of epoch 124 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 160, time: 0.125, data: 0.005) D_A: 0.232 G_A: 0.230 cycle_A: 0.144 idt_A: 0.308 D_B: 0.262 G_B: 0.331 cycle_B: 0.623 idt_B: 0.053 \n",
      "saving the latest model (epoch 125, total_iters 20000)\n",
      "saving the model at the end of epoch 125, iters 20000\n",
      "End of epoch 125 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "End of epoch 126 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "End of epoch 127 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 80, time: 0.125, data: 0.170) D_A: 0.235 G_A: 0.247 cycle_A: 0.145 idt_A: 0.228 D_B: 0.242 G_B: 0.315 cycle_B: 0.423 idt_B: 0.056 \n",
      "End of epoch 128 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "End of epoch 129 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 160, time: 0.134, data: 0.006) D_A: 0.196 G_A: 0.310 cycle_A: 0.140 idt_A: 0.302 D_B: 0.246 G_B: 0.239 cycle_B: 0.608 idt_B: 0.057 \n",
      "saving the model at the end of epoch 130, iters 20800\n",
      "End of epoch 130 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "End of epoch 131 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "End of epoch 132 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 80, time: 0.124, data: 0.172) D_A: 0.228 G_A: 0.295 cycle_A: 0.127 idt_A: 0.282 D_B: 0.246 G_B: 0.185 cycle_B: 0.571 idt_B: 0.051 \n",
      "End of epoch 133 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "End of epoch 134 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 160, time: 0.136, data: 0.004) D_A: 0.221 G_A: 0.415 cycle_A: 0.105 idt_A: 0.232 D_B: 0.238 G_B: 0.294 cycle_B: 0.463 idt_B: 0.044 \n",
      "saving the model at the end of epoch 135, iters 21600\n",
      "End of epoch 135 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "End of epoch 136 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "End of epoch 137 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 80, time: 0.126, data: 0.167) D_A: 0.141 G_A: 0.672 cycle_A: 0.097 idt_A: 0.301 D_B: 0.236 G_B: 0.268 cycle_B: 0.572 idt_B: 0.040 \n",
      "End of epoch 138 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "End of epoch 139 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 160, time: 0.127, data: 0.005) D_A: 0.234 G_A: 0.281 cycle_A: 0.120 idt_A: 0.221 D_B: 0.248 G_B: 0.253 cycle_B: 0.427 idt_B: 0.040 \n",
      "saving the model at the end of epoch 140, iters 22400\n",
      "End of epoch 140 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "End of epoch 141 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "End of epoch 142 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 80, time: 0.136, data: 0.173) D_A: 0.237 G_A: 0.247 cycle_A: 0.141 idt_A: 0.222 D_B: 0.247 G_B: 0.237 cycle_B: 0.420 idt_B: 0.047 \n",
      "End of epoch 143 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "End of epoch 144 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 160, time: 0.127, data: 0.005) D_A: 0.228 G_A: 0.345 cycle_A: 0.085 idt_A: 0.227 D_B: 0.248 G_B: 0.210 cycle_B: 0.358 idt_B: 0.036 \n",
      "saving the model at the end of epoch 145, iters 23200\n",
      "End of epoch 145 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "End of epoch 146 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "End of epoch 147 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 80, time: 0.137, data: 0.168) D_A: 0.182 G_A: 0.455 cycle_A: 0.135 idt_A: 0.239 D_B: 0.231 G_B: 0.266 cycle_B: 0.435 idt_B: 0.050 \n",
      "End of epoch 148 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "End of epoch 149 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 160, time: 0.130, data: 0.005) D_A: 0.190 G_A: 0.305 cycle_A: 0.135 idt_A: 0.184 D_B: 0.240 G_B: 0.243 cycle_B: 0.315 idt_B: 0.050 \n",
      "saving the model at the end of epoch 150, iters 24000\n",
      "End of epoch 150 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "End of epoch 151 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "End of epoch 152 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 80, time: 0.138, data: 0.173) D_A: 0.203 G_A: 0.458 cycle_A: 0.082 idt_A: 0.233 D_B: 0.261 G_B: 0.229 cycle_B: 0.348 idt_B: 0.030 \n",
      "End of epoch 153 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "End of epoch 154 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 160, time: 0.129, data: 0.005) D_A: 0.163 G_A: 0.280 cycle_A: 0.103 idt_A: 0.265 D_B: 0.245 G_B: 0.257 cycle_B: 0.691 idt_B: 0.045 \n",
      "saving the model at the end of epoch 155, iters 24800\n",
      "End of epoch 155 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "End of epoch 156 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "End of epoch 157 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 80, time: 0.129, data: 0.175) D_A: 0.220 G_A: 0.247 cycle_A: 0.108 idt_A: 0.284 D_B: 0.247 G_B: 0.208 cycle_B: 0.578 idt_B: 0.042 \n",
      "End of epoch 158 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "End of epoch 159 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 160, time: 0.138, data: 0.004) D_A: 0.198 G_A: 0.287 cycle_A: 0.088 idt_A: 0.285 D_B: 0.236 G_B: 0.205 cycle_B: 0.479 idt_B: 0.034 \n",
      "saving the model at the end of epoch 160, iters 25600\n",
      "End of epoch 160 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "End of epoch 161 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "End of epoch 162 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 80, time: 0.132, data: 0.165) D_A: 0.231 G_A: 0.293 cycle_A: 0.094 idt_A: 0.270 D_B: 0.251 G_B: 0.423 cycle_B: 0.477 idt_B: 0.036 \n",
      "End of epoch 163 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "End of epoch 164 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 160, time: 0.139, data: 0.004) D_A: 0.187 G_A: 0.361 cycle_A: 0.095 idt_A: 0.202 D_B: 0.240 G_B: 0.230 cycle_B: 0.452 idt_B: 0.036 \n",
      "saving the model at the end of epoch 165, iters 26400\n",
      "End of epoch 165 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "End of epoch 166 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "End of epoch 167 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 80, time: 0.132, data: 0.171) D_A: 0.203 G_A: 0.326 cycle_A: 0.079 idt_A: 0.224 D_B: 0.239 G_B: 0.254 cycle_B: 0.517 idt_B: 0.033 \n",
      "End of epoch 168 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "End of epoch 169 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 160, time: 0.140, data: 0.004) D_A: 0.204 G_A: 0.307 cycle_A: 0.086 idt_A: 0.228 D_B: 0.225 G_B: 0.284 cycle_B: 0.342 idt_B: 0.039 \n",
      "saving the model at the end of epoch 170, iters 27200\n",
      "End of epoch 170 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "End of epoch 171 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "End of epoch 172 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 80, time: 0.132, data: 0.175) D_A: 0.246 G_A: 0.250 cycle_A: 0.066 idt_A: 0.168 D_B: 0.258 G_B: 0.465 cycle_B: 0.285 idt_B: 0.029 \n",
      "End of epoch 173 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "End of epoch 174 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 160, time: 0.140, data: 0.005) D_A: 0.219 G_A: 0.387 cycle_A: 0.090 idt_A: 0.252 D_B: 0.236 G_B: 0.359 cycle_B: 0.439 idt_B: 0.038 \n",
      "saving the model at the end of epoch 175, iters 28000\n",
      "End of epoch 175 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "End of epoch 176 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "End of epoch 177 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 80, time: 0.132, data: 0.172) D_A: 0.194 G_A: 0.319 cycle_A: 0.064 idt_A: 0.237 D_B: 0.227 G_B: 0.304 cycle_B: 0.406 idt_B: 0.028 \n",
      "End of epoch 178 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "End of epoch 179 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 160, time: 0.142, data: 0.005) D_A: 0.210 G_A: 0.283 cycle_A: 0.068 idt_A: 0.219 D_B: 0.231 G_B: 0.264 cycle_B: 0.385 idt_B: 0.031 \n",
      "saving the model at the end of epoch 180, iters 28800\n",
      "End of epoch 180 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "End of epoch 181 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "End of epoch 182 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 80, time: 0.142, data: 0.176) D_A: 0.273 G_A: 0.322 cycle_A: 0.071 idt_A: 0.214 D_B: 0.219 G_B: 0.331 cycle_B: 0.305 idt_B: 0.031 \n",
      "End of epoch 183 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "End of epoch 184 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 160, time: 0.134, data: 0.005) D_A: 0.214 G_A: 0.260 cycle_A: 0.072 idt_A: 0.208 D_B: 0.224 G_B: 0.250 cycle_B: 0.284 idt_B: 0.034 \n",
      "saving the model at the end of epoch 185, iters 29600\n",
      "End of epoch 185 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "End of epoch 186 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "End of epoch 187 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 80, time: 0.143, data: 0.175) D_A: 0.195 G_A: 0.301 cycle_A: 0.080 idt_A: 0.254 D_B: 0.222 G_B: 0.268 cycle_B: 0.352 idt_B: 0.036 \n",
      "saving the latest model (epoch 188, total_iters 30000)\n",
      "End of epoch 188 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "End of epoch 189 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 160, time: 0.134, data: 0.004) D_A: 0.225 G_A: 0.415 cycle_A: 0.067 idt_A: 0.208 D_B: 0.222 G_B: 0.252 cycle_B: 0.182 idt_B: 0.032 \n",
      "saving the model at the end of epoch 190, iters 30400\n",
      "End of epoch 190 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "End of epoch 191 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "End of epoch 192 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 80, time: 0.143, data: 0.171) D_A: 0.198 G_A: 0.320 cycle_A: 0.063 idt_A: 0.222 D_B: 0.235 G_B: 0.229 cycle_B: 0.256 idt_B: 0.028 \n",
      "End of epoch 193 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "End of epoch 194 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 160, time: 0.135, data: 0.004) D_A: 0.232 G_A: 0.310 cycle_A: 0.069 idt_A: 0.198 D_B: 0.220 G_B: 0.296 cycle_B: 0.247 idt_B: 0.031 \n",
      "saving the model at the end of epoch 195, iters 31200\n",
      "End of epoch 195 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "End of epoch 196 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "End of epoch 197 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 80, time: 0.144, data: 0.174) D_A: 0.238 G_A: 0.245 cycle_A: 0.064 idt_A: 0.195 D_B: 0.214 G_B: 0.297 cycle_B: 0.221 idt_B: 0.029 \n",
      "End of epoch 198 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "End of epoch 199 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 160, time: 0.144, data: 0.004) D_A: 0.246 G_A: 0.283 cycle_A: 0.062 idt_A: 0.221 D_B: 0.224 G_B: 0.306 cycle_B: 0.249 idt_B: 0.028 \n",
      "saving the model at the end of epoch 200, iters 32000\n",
      "End of epoch 200 / 200 \t Time Taken: 15 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot data/mnist_blur_pairs_small --name cycle_gan_mnist_small --model cycle_gan --display_id -1 --batch_size 16\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "W-Net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
