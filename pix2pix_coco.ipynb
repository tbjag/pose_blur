{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /media/Data_2/                \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: blurred_coco                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 1000\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/blurred_coco/web...\n",
      "/home/project/anaconda3/envs/W-Net/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.021, data: 0.091) G_GAN: 0.728 G_L1: 15.511 D_real: 0.666 D_fake: 0.825 \n",
      "(epoch: 1, iters: 200, time: 0.021, data: 0.001) G_GAN: 0.734 G_L1: 11.753 D_real: 0.744 D_fake: 0.655 \n",
      "(epoch: 1, iters: 300, time: 0.021, data: 0.001) G_GAN: 0.878 G_L1: 10.240 D_real: 0.683 D_fake: 0.685 \n",
      "(epoch: 1, iters: 400, time: 0.089, data: 0.001) G_GAN: 0.748 G_L1: 5.116 D_real: 0.642 D_fake: 0.933 \n",
      "(epoch: 1, iters: 500, time: 0.021, data: 0.001) G_GAN: 1.750 G_L1: 6.193 D_real: 1.123 D_fake: 0.948 \n",
      "(epoch: 1, iters: 600, time: 0.021, data: 0.001) G_GAN: 1.275 G_L1: 7.131 D_real: 0.707 D_fake: 0.351 \n",
      "(epoch: 1, iters: 700, time: 0.021, data: 0.001) G_GAN: 1.328 G_L1: 16.163 D_real: 0.471 D_fake: 0.383 \n",
      "(epoch: 1, iters: 800, time: 0.021, data: 0.001) G_GAN: 1.260 G_L1: 10.664 D_real: 0.549 D_fake: 0.300 \n",
      "(epoch: 1, iters: 900, time: 0.021, data: 0.001) G_GAN: 2.607 G_L1: 7.446 D_real: 0.090 D_fake: 0.482 \n",
      "(epoch: 1, iters: 1000, time: 0.021, data: 0.001) G_GAN: 2.614 G_L1: 11.655 D_real: 0.095 D_fake: 0.128 \n",
      "End of epoch 1 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 100, time: 0.021, data: 0.091) G_GAN: 2.598 G_L1: 8.135 D_real: 0.077 D_fake: 0.764 \n",
      "(epoch: 2, iters: 200, time: 0.069, data: 0.001) G_GAN: 2.408 G_L1: 10.733 D_real: 0.046 D_fake: 0.129 \n",
      "(epoch: 2, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.813 G_L1: 7.225 D_real: 0.446 D_fake: 0.040 \n",
      "(epoch: 2, iters: 400, time: 0.020, data: 0.001) G_GAN: 4.197 G_L1: 7.750 D_real: 0.262 D_fake: 0.008 \n",
      "(epoch: 2, iters: 500, time: 0.020, data: 0.001) G_GAN: 2.568 G_L1: 8.768 D_real: 0.055 D_fake: 0.434 \n",
      "(epoch: 2, iters: 600, time: 0.020, data: 0.001) G_GAN: 2.517 G_L1: 6.090 D_real: 0.231 D_fake: 1.054 \n",
      "(epoch: 2, iters: 700, time: 0.021, data: 0.001) G_GAN: 1.863 G_L1: 5.815 D_real: 0.200 D_fake: 0.639 \n",
      "(epoch: 2, iters: 800, time: 0.020, data: 0.001) G_GAN: 1.639 G_L1: 9.809 D_real: 0.259 D_fake: 1.259 \n",
      "(epoch: 2, iters: 900, time: 0.020, data: 0.001) G_GAN: 3.899 G_L1: 10.801 D_real: 0.038 D_fake: 0.030 \n",
      "(epoch: 2, iters: 1000, time: 0.093, data: 0.001) G_GAN: 3.184 G_L1: 5.656 D_real: 0.926 D_fake: 0.081 \n",
      "End of epoch 2 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.022, data: 0.092) G_GAN: 4.638 G_L1: 8.271 D_real: 0.157 D_fake: 0.010 \n",
      "(epoch: 3, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.837 G_L1: 5.336 D_real: 0.228 D_fake: 0.651 \n",
      "(epoch: 3, iters: 300, time: 0.021, data: 0.001) G_GAN: 4.330 G_L1: 5.021 D_real: 0.020 D_fake: 0.026 \n",
      "(epoch: 3, iters: 400, time: 0.071, data: 0.001) G_GAN: 5.635 G_L1: 8.006 D_real: 0.178 D_fake: 0.004 \n",
      "(epoch: 3, iters: 500, time: 0.021, data: 0.001) G_GAN: 4.746 G_L1: 9.695 D_real: 0.607 D_fake: 0.011 \n",
      "(epoch: 3, iters: 600, time: 0.021, data: 0.001) G_GAN: 2.767 G_L1: 7.765 D_real: 1.811 D_fake: 0.030 \n",
      "(epoch: 3, iters: 700, time: 0.020, data: 0.001) G_GAN: 3.491 G_L1: 5.056 D_real: 0.032 D_fake: 0.037 \n",
      "(epoch: 3, iters: 800, time: 0.020, data: 0.001) G_GAN: 3.713 G_L1: 7.658 D_real: 0.014 D_fake: 0.069 \n",
      "(epoch: 3, iters: 900, time: 0.020, data: 0.001) G_GAN: 2.883 G_L1: 6.859 D_real: 0.434 D_fake: 0.081 \n",
      "(epoch: 3, iters: 1000, time: 0.020, data: 0.001) G_GAN: 4.379 G_L1: 7.516 D_real: 0.044 D_fake: 0.016 \n",
      "End of epoch 3 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 100, time: 0.021, data: 0.096) G_GAN: 7.282 G_L1: 11.232 D_real: 0.013 D_fake: 0.001 \n",
      "(epoch: 4, iters: 200, time: 0.069, data: 0.001) G_GAN: 5.994 G_L1: 11.070 D_real: 0.024 D_fake: 0.003 \n",
      "(epoch: 4, iters: 300, time: 0.021, data: 0.001) G_GAN: 6.195 G_L1: 12.490 D_real: 0.001 D_fake: 0.004 \n",
      "(epoch: 4, iters: 400, time: 0.021, data: 0.001) G_GAN: 7.677 G_L1: 6.366 D_real: 0.008 D_fake: 0.001 \n",
      "(epoch: 4, iters: 500, time: 0.021, data: 0.001) G_GAN: 4.127 G_L1: 13.334 D_real: 0.188 D_fake: 0.017 \n",
      "(epoch: 4, iters: 600, time: 0.021, data: 0.001) G_GAN: 4.521 G_L1: 11.380 D_real: 0.945 D_fake: 0.080 \n",
      "(epoch: 4, iters: 700, time: 0.021, data: 0.001) G_GAN: 5.463 G_L1: 8.868 D_real: 0.039 D_fake: 0.582 \n",
      "(epoch: 4, iters: 800, time: 0.021, data: 0.001) G_GAN: 2.959 G_L1: 6.986 D_real: 0.018 D_fake: 0.079 \n",
      "(epoch: 4, iters: 900, time: 0.021, data: 0.001) G_GAN: 1.590 G_L1: 8.315 D_real: 0.182 D_fake: 0.408 \n",
      "(epoch: 4, iters: 1000, time: 0.075, data: 0.001) G_GAN: 2.540 G_L1: 5.308 D_real: 1.892 D_fake: 0.017 \n",
      "End of epoch 4 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.021, data: 0.095) G_GAN: 4.483 G_L1: 5.807 D_real: 0.174 D_fake: 0.006 \n",
      "(epoch: 5, iters: 200, time: 0.021, data: 0.001) G_GAN: 3.001 G_L1: 10.187 D_real: 0.003 D_fake: 0.282 \n",
      "(epoch: 5, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.597 G_L1: 7.066 D_real: 0.007 D_fake: 0.345 \n",
      "(epoch: 5, iters: 400, time: 0.072, data: 0.001) G_GAN: 7.684 G_L1: 13.348 D_real: 0.058 D_fake: 0.001 \n",
      "(epoch: 5, iters: 500, time: 0.021, data: 0.001) G_GAN: 7.165 G_L1: 10.227 D_real: 0.003 D_fake: 0.001 \n",
      "(epoch: 5, iters: 600, time: 0.021, data: 0.001) G_GAN: 3.331 G_L1: 7.509 D_real: 0.001 D_fake: 0.104 \n",
      "(epoch: 5, iters: 700, time: 0.021, data: 0.001) G_GAN: 5.982 G_L1: 6.016 D_real: 0.043 D_fake: 0.003 \n",
      "(epoch: 5, iters: 800, time: 0.021, data: 0.001) G_GAN: 5.463 G_L1: 8.935 D_real: 0.181 D_fake: 0.009 \n",
      "(epoch: 5, iters: 900, time: 0.021, data: 0.001) G_GAN: 6.250 G_L1: 7.853 D_real: 0.000 D_fake: 0.003 \n",
      "(epoch: 5, iters: 1000, time: 0.021, data: 0.001) G_GAN: 6.068 G_L1: 13.047 D_real: 0.002 D_fake: 0.004 \n",
      "saving the latest model (epoch 5, total_iters 5000)\n",
      "saving the model at the end of epoch 5, iters 5000\n",
      "End of epoch 5 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.021, data: 0.100) G_GAN: 3.360 G_L1: 4.457 D_real: 0.005 D_fake: 0.053 \n",
      "(epoch: 6, iters: 200, time: 0.086, data: 0.001) G_GAN: 2.784 G_L1: 7.882 D_real: 0.267 D_fake: 0.087 \n",
      "(epoch: 6, iters: 300, time: 0.022, data: 0.001) G_GAN: 7.567 G_L1: 6.566 D_real: 0.004 D_fake: 0.001 \n",
      "(epoch: 6, iters: 400, time: 0.022, data: 0.001) G_GAN: 6.849 G_L1: 8.625 D_real: 0.005 D_fake: 0.002 \n",
      "(epoch: 6, iters: 500, time: 0.022, data: 0.001) G_GAN: 4.355 G_L1: 7.136 D_real: 0.049 D_fake: 0.925 \n",
      "(epoch: 6, iters: 600, time: 0.021, data: 0.001) G_GAN: 6.003 G_L1: 7.870 D_real: 0.174 D_fake: 0.005 \n",
      "(epoch: 6, iters: 700, time: 0.021, data: 0.001) G_GAN: 3.663 G_L1: 5.604 D_real: 0.011 D_fake: 0.047 \n",
      "(epoch: 6, iters: 800, time: 0.021, data: 0.001) G_GAN: 6.639 G_L1: 5.680 D_real: 0.001 D_fake: 0.002 \n",
      "(epoch: 6, iters: 900, time: 0.020, data: 0.001) G_GAN: 1.094 G_L1: 6.334 D_real: 0.242 D_fake: 0.446 \n",
      "(epoch: 6, iters: 1000, time: 0.062, data: 0.001) G_GAN: 1.710 G_L1: 14.481 D_real: 0.288 D_fake: 0.118 \n",
      "End of epoch 6 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.022, data: 0.094) G_GAN: 1.935 G_L1: 8.869 D_real: 0.288 D_fake: 0.143 \n",
      "(epoch: 7, iters: 200, time: 0.022, data: 0.001) G_GAN: 5.248 G_L1: 5.792 D_real: 0.003 D_fake: 0.008 \n",
      "(epoch: 7, iters: 300, time: 0.022, data: 0.001) G_GAN: 7.033 G_L1: 8.572 D_real: 0.007 D_fake: 0.002 \n",
      "(epoch: 7, iters: 400, time: 0.079, data: 0.001) G_GAN: 3.275 G_L1: 6.268 D_real: 0.114 D_fake: 0.076 \n",
      "(epoch: 7, iters: 500, time: 0.022, data: 0.001) G_GAN: 5.856 G_L1: 6.725 D_real: 0.007 D_fake: 0.003 \n",
      "(epoch: 7, iters: 600, time: 0.021, data: 0.001) G_GAN: 4.363 G_L1: 4.414 D_real: 0.003 D_fake: 0.014 \n",
      "(epoch: 7, iters: 700, time: 0.022, data: 0.001) G_GAN: 2.183 G_L1: 5.937 D_real: 0.435 D_fake: 0.128 \n",
      "(epoch: 7, iters: 800, time: 0.020, data: 0.001) G_GAN: 4.584 G_L1: 6.848 D_real: 0.004 D_fake: 0.018 \n",
      "(epoch: 7, iters: 900, time: 0.020, data: 0.001) G_GAN: 6.995 G_L1: 12.437 D_real: 0.001 D_fake: 0.001 \n",
      "(epoch: 7, iters: 1000, time: 0.021, data: 0.001) G_GAN: 7.535 G_L1: 11.987 D_real: 0.001 D_fake: 0.001 \n",
      "End of epoch 7 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 100, time: 0.020, data: 0.095) G_GAN: 7.878 G_L1: 14.427 D_real: 0.029 D_fake: 0.000 \n",
      "(epoch: 8, iters: 200, time: 0.095, data: 0.001) G_GAN: 5.268 G_L1: 6.540 D_real: 0.238 D_fake: 0.004 \n",
      "(epoch: 8, iters: 300, time: 0.021, data: 0.001) G_GAN: 5.481 G_L1: 5.265 D_real: 0.008 D_fake: 0.005 \n",
      "(epoch: 8, iters: 400, time: 0.021, data: 0.001) G_GAN: 4.330 G_L1: 9.223 D_real: 0.659 D_fake: 0.058 \n",
      "(epoch: 8, iters: 500, time: 0.021, data: 0.001) G_GAN: 3.624 G_L1: 4.343 D_real: 0.006 D_fake: 0.061 \n",
      "(epoch: 8, iters: 600, time: 0.020, data: 0.001) G_GAN: 5.273 G_L1: 7.107 D_real: 0.017 D_fake: 0.010 \n",
      "(epoch: 8, iters: 700, time: 0.021, data: 0.001) G_GAN: 7.660 G_L1: 6.126 D_real: 0.067 D_fake: 0.001 \n",
      "(epoch: 8, iters: 800, time: 0.021, data: 0.001) G_GAN: 6.029 G_L1: 8.886 D_real: 0.031 D_fake: 0.002 \n",
      "(epoch: 8, iters: 900, time: 0.021, data: 0.001) G_GAN: 4.699 G_L1: 9.901 D_real: 0.000 D_fake: 0.019 \n",
      "(epoch: 8, iters: 1000, time: 0.071, data: 0.001) G_GAN: 3.997 G_L1: 5.289 D_real: 0.031 D_fake: 0.026 \n",
      "End of epoch 8 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.020, data: 0.093) G_GAN: 5.119 G_L1: 5.758 D_real: 0.000 D_fake: 0.011 \n",
      "(epoch: 9, iters: 200, time: 0.022, data: 0.001) G_GAN: 3.421 G_L1: 7.231 D_real: 0.003 D_fake: 0.066 \n",
      "(epoch: 9, iters: 300, time: 0.022, data: 0.001) G_GAN: 3.719 G_L1: 7.081 D_real: 0.001 D_fake: 0.916 \n",
      "(epoch: 9, iters: 400, time: 0.093, data: 0.001) G_GAN: 7.472 G_L1: 9.204 D_real: 0.001 D_fake: 0.001 \n",
      "(epoch: 9, iters: 500, time: 0.022, data: 0.001) G_GAN: 10.066 G_L1: 8.550 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 9, iters: 600, time: 0.022, data: 0.001) G_GAN: 4.601 G_L1: 4.651 D_real: 0.004 D_fake: 0.015 \n",
      "(epoch: 9, iters: 700, time: 0.020, data: 0.001) G_GAN: 5.882 G_L1: 6.365 D_real: 0.000 D_fake: 0.003 \n",
      "(epoch: 9, iters: 800, time: 0.020, data: 0.001) G_GAN: 6.797 G_L1: 5.135 D_real: 0.010 D_fake: 0.001 \n",
      "(epoch: 9, iters: 900, time: 0.021, data: 0.001) G_GAN: 6.957 G_L1: 3.822 D_real: 0.012 D_fake: 0.001 \n",
      "(epoch: 9, iters: 1000, time: 0.021, data: 0.001) G_GAN: 5.497 G_L1: 4.998 D_real: 0.015 D_fake: 0.007 \n",
      "End of epoch 9 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 100, time: 0.022, data: 0.100) G_GAN: 4.497 G_L1: 6.542 D_real: 0.036 D_fake: 0.018 \n",
      "(epoch: 10, iters: 200, time: 0.102, data: 0.001) G_GAN: 3.333 G_L1: 7.049 D_real: 0.002 D_fake: 0.386 \n",
      "(epoch: 10, iters: 300, time: 0.022, data: 0.001) G_GAN: 5.776 G_L1: 7.943 D_real: 0.303 D_fake: 0.004 \n",
      "(epoch: 10, iters: 400, time: 0.022, data: 0.001) G_GAN: 6.361 G_L1: 7.781 D_real: 0.062 D_fake: 0.003 \n",
      "(epoch: 10, iters: 500, time: 0.022, data: 0.001) G_GAN: 5.371 G_L1: 8.577 D_real: 0.000 D_fake: 0.007 \n",
      "(epoch: 10, iters: 600, time: 0.021, data: 0.001) G_GAN: 3.677 G_L1: 3.696 D_real: 0.000 D_fake: 0.543 \n",
      "(epoch: 10, iters: 700, time: 0.022, data: 0.001) G_GAN: 4.605 G_L1: 4.432 D_real: 0.029 D_fake: 0.013 \n",
      "(epoch: 10, iters: 800, time: 0.022, data: 0.001) G_GAN: 9.621 G_L1: 5.653 D_real: 0.438 D_fake: 0.000 \n",
      "(epoch: 10, iters: 900, time: 0.022, data: 0.001) G_GAN: 3.067 G_L1: 3.631 D_real: 0.010 D_fake: 0.066 \n",
      "(epoch: 10, iters: 1000, time: 0.100, data: 0.001) G_GAN: 7.031 G_L1: 7.459 D_real: 0.000 D_fake: 0.002 \n",
      "saving the latest model (epoch 10, total_iters 10000)\n",
      "saving the model at the end of epoch 10, iters 10000\n",
      "End of epoch 10 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.021, data: 0.110) G_GAN: 5.440 G_L1: 8.155 D_real: 0.033 D_fake: 0.006 \n",
      "(epoch: 11, iters: 200, time: 0.021, data: 0.001) G_GAN: 8.783 G_L1: 6.880 D_real: 0.002 D_fake: 0.000 \n",
      "(epoch: 11, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.163 G_L1: 5.881 D_real: 0.149 D_fake: 2.816 \n",
      "(epoch: 11, iters: 400, time: 0.079, data: 0.001) G_GAN: 8.927 G_L1: 11.570 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 11, iters: 500, time: 0.021, data: 0.001) G_GAN: 6.318 G_L1: 4.668 D_real: 0.003 D_fake: 0.006 \n",
      "(epoch: 11, iters: 600, time: 0.021, data: 0.001) G_GAN: 3.362 G_L1: 5.741 D_real: 0.027 D_fake: 0.088 \n",
      "(epoch: 11, iters: 700, time: 0.021, data: 0.001) G_GAN: 6.016 G_L1: 4.562 D_real: 0.003 D_fake: 0.004 \n",
      "(epoch: 11, iters: 800, time: 0.021, data: 0.001) G_GAN: 5.079 G_L1: 6.438 D_real: 0.116 D_fake: 0.008 \n",
      "(epoch: 11, iters: 900, time: 0.021, data: 0.001) G_GAN: 4.064 G_L1: 5.808 D_real: 0.068 D_fake: 0.032 \n",
      "(epoch: 11, iters: 1000, time: 0.021, data: 0.001) G_GAN: 1.879 G_L1: 6.304 D_real: 0.188 D_fake: 0.303 \n",
      "End of epoch 11 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/project/GAN_project/pose_blur/train.py\", line 51, in <module>\n",
      "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
      "  File \"/home/project/GAN_project/pose_blur/models/pix2pix_model.py\", line 82, in set_input\n",
      "    self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot /media/Data_2/ --name blurred_coco --model pix2pix --direction AtoB --display_id -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "W-Net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
